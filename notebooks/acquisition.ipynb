{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition. 0 Data Structure of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all modules\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global stuff\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sql extension for jupyter\n",
    "%load_ext sql\n",
    "%config SqlMagic.autocommit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load database\n",
    "%sql sqlite:///../data/raw/raw_data_project_m1.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///../data/raw/raw_data_project_m1.db\n",
      "Done.\n",
      "Returning data to local variable tables_structure\n"
     ]
    }
   ],
   "source": [
    "%%sql tables_structure <<\n",
    "\n",
    "select * \n",
    "from \n",
    "    sqlite_master\n",
    "\n",
    "where \n",
    "    type='table' AND\n",
    "    name NOT LIKE 'sqlite_%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENING TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///../data/raw/raw_data_project_m1.db\n",
      "Done.\n",
      "Returning data to local variable personal_info\n"
     ]
    }
   ],
   "source": [
    "%%sql personal_info <<\n",
    "\n",
    "select * from personal_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///../data/raw/raw_data_project_m1.db\n",
      "Done.\n",
      "Returning data to local variable country_info\n"
     ]
    }
   ],
   "source": [
    "%%sql country_info <<\n",
    "\n",
    "select * from country_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///../data/raw/raw_data_project_m1.db\n",
      "Done.\n",
      "Returning data to local variable career_info\n"
     ]
    }
   ],
   "source": [
    "%%sql career_info <<\n",
    "\n",
    "select * from career_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///../data/raw/raw_data_project_m1.db\n",
      "Done.\n",
      "Returning data to local variable poll_info\n"
     ]
    }
   ],
   "source": [
    "%%sql poll_info <<\n",
    "\n",
    "select * from poll_info;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal_info = personal_info.DataFrame()\n",
    "df_country_info = country_info.DataFrame()\n",
    "df_career_info = career_info.DataFrame()\n",
    "df_poll_info = poll_info.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictCountries(web_page):\n",
    "    \"\"\"\n",
    "    Note_1: Only works for a part of the web scrapping, therefore dict lenght is limited to countries_in_eu\n",
    "    Note_2: 'https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Country_codes'\n",
    "    ------------------------------------------------------------------------------------------------    \n",
    "    INPUT: url\n",
    "    OUTPUT: dict -> 'SP': 'Spain'\n",
    "\n",
    "    \"\"\"\n",
    "    countries_in_europe = 45\n",
    "        \n",
    "    url= web_page\n",
    "    html = requests.get(url).content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    table = soup.find_all('table')\n",
    "    \n",
    "    countries_list = list(filter(None, \n",
    "                                 [re.sub('\\n','', re.sub('</td>','', re.sub('^<td>','', str(i)))) \n",
    "                                  for i in soup.find_all('td')]))\n",
    "\n",
    "    \"\"\"\n",
    "    Note\n",
    "    ------------------------------------------------------------------------------------------------\n",
    "    Esta parte es mejorable: Kosovo* y CH_X_HK etc ...  \n",
    "    \"\"\"\n",
    "    countries_names = [(''.join(i.strip())).split('<')[0] for k, i in enumerate(countries_list) if k%2 == 0]\n",
    "    countries_alpha2= [(''.join(i.strip())).split('<')[0][1:3] for k, i in enumerate(countries_list) if k%2 != 0]\n",
    "    \n",
    "    countries_dict = dict(zip(countries_alpha2[:countries_in_europe], countries_names[:countries_in_europe]))\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    IMPERFECT IMPLEMENTATIONS (as seen in wikipedia)\n",
    "    ------------------------------------------------------------------------------------------------\n",
    "    The European Commission generally uses ISO 3166-1 alpha-2 codes with two exceptions: \n",
    "    EL (not GR) is used to represent Greece, and UK (not GB) is used to represent the United Kingdom\n",
    "    \"\"\"\n",
    "    countries_dict = dict(zip(countries_alpha2[:countries_in_europe], countries_names[:countries_in_europe]))\n",
    "    countries_dict['GB'] = 'United Kingdom'\n",
    "    countries_dict['GR'] = 'Greece'\n",
    "\n",
    "    return countries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = get_dictCountries('https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Country_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hay 28 paises y me he sacado 45 de lap pag (TODA EUROPA) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DICTIONARY TO REPLACE WITH WEB SCRAPPING\n",
    "\n",
    "countries_code_alpha_2 = {\n",
    "    'AT' : 'Austria',   'BE' : 'Belgium',        'BG' : 'Bulgaria',  'CY' : 'Cyprus',     'CZ' : 'Czechia',\n",
    "    'DE' : 'Germany',   'DK' : 'Denmark',        'EE' : 'Estonia',   'ES' : 'Spain',      'FI' : 'Finland', \n",
    "    'FR' : 'France',    'GB' : 'United Kingdom', 'GR' : 'Greece',    'HR' : 'Croatia',    'HU' : 'Hungary', \n",
    "    'IE' : 'Ireland',   'IT' : 'Italy',          'LT' : 'Lithuania', 'LU' : 'Luxembourg', 'LV' : 'Latvia',  \n",
    "    'MT' : 'Malta',     'NL' : 'Netherlands',    'PL' : 'Poland',    'PT' : 'Portugal',   'RO' : 'Romania',\n",
    "    'SE' : 'Sweden',    'SI' : 'Slovenia',       'SK' : 'Slovakia',\n",
    "} \n",
    "\"\"\"Hay 28 paises y me he sacado 45 de lap pag (TODA EUROPA) \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictEuropeanCountries():\n",
    "    wiki_url= 'https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2'\n",
    "    url= 'https://www.euro.who.int/en/countries'\n",
    "    \n",
    "    html_wikipage = requests.get(wiki_url).content\n",
    "    html_eurocountries = requests.get(url).content\n",
    "        \n",
    "    countries_list = pd.read_html(html_wikipage, header=0)[2]\n",
    "    countries_dict = dict(zip(countries_list['Code'], countries_list['Country name (using title case)']))\n",
    "\n",
    "    soup = BeautifulSoup(html_eurocountries, 'lxml')\n",
    "    table = soup.find_all('section', {'class':'clearfix'})\n",
    "\n",
    "    all_contries = [content.text for content in table]\n",
    "    eu_countries = list(filter(None, all_contries[0].split('\\n')))\n",
    "\n",
    "    european_countries_values = [val for k,val in countries_dict.items() for eu_c in eu_countries if val == eu_c]\n",
    "    european_countries_key = [k for k,val in countries_dict.items() for eu_c in eu_countries if val == eu_c]\n",
    "\n",
    "    return dict(zip(european_countries_key, european_countries_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_countries = get_dictEuropeanCountries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AD': 'Andorra',\n",
       " 'AL': 'Albania',\n",
       " 'AM': 'Armenia',\n",
       " 'AT': 'Austria',\n",
       " 'AZ': 'Azerbaijan',\n",
       " 'BA': 'Bosnia and Herzegovina',\n",
       " 'BE': 'Belgium',\n",
       " 'BG': 'Bulgaria',\n",
       " 'BY': 'Belarus',\n",
       " 'CH': 'Switzerland',\n",
       " 'CY': 'Cyprus',\n",
       " 'CZ': 'Czechia',\n",
       " 'DE': 'Germany',\n",
       " 'DK': 'Denmark',\n",
       " 'EE': 'Estonia',\n",
       " 'ES': 'Spain',\n",
       " 'FI': 'Finland',\n",
       " 'FR': 'France',\n",
       " 'GB': 'United Kingdom of Great Britain and Northern Ireland',\n",
       " 'GE': 'Georgia',\n",
       " 'GR': 'Greece',\n",
       " 'HR': 'Croatia',\n",
       " 'HU': 'Hungary',\n",
       " 'IE': 'Ireland',\n",
       " 'IL': 'Israel',\n",
       " 'IS': 'Iceland',\n",
       " 'IT': 'Italy',\n",
       " 'KG': 'Kyrgyzstan',\n",
       " 'KZ': 'Kazakhstan',\n",
       " 'LT': 'Lithuania',\n",
       " 'LU': 'Luxembourg',\n",
       " 'LV': 'Latvia',\n",
       " 'MC': 'Monaco',\n",
       " 'ME': 'Montenegro',\n",
       " 'MK': 'North Macedonia',\n",
       " 'MT': 'Malta',\n",
       " 'NL': 'Netherlands',\n",
       " 'NO': 'Norway',\n",
       " 'PL': 'Poland',\n",
       " 'PT': 'Portugal',\n",
       " 'RO': 'Romania',\n",
       " 'RS': 'Serbia',\n",
       " 'RU': 'Russian Federation',\n",
       " 'SE': 'Sweden',\n",
       " 'SI': 'Slovenia',\n",
       " 'SK': 'Slovakia',\n",
       " 'SM': 'San Marino',\n",
       " 'TJ': 'Tajikistan',\n",
       " 'TM': 'Turkmenistan',\n",
       " 'TR': 'Turkey',\n",
       " 'UA': 'Ukraine',\n",
       " 'UZ': 'Uzbekistan'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "european_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictWorldCountries():\n",
    "    wiki_url= 'https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2'\n",
    "    \n",
    "    html_wikipage = requests.get(wiki_url).content\n",
    "        \n",
    "    countries_list = pd.read_html(html_wikipage, header=0)[2]\n",
    "    countries_dict = dict(zip(countries_list['Code'], countries_list['Country name (using title case)']))\n",
    "\n",
    "    return countries_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-19-e71b6541524f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-e71b6541524f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    input('Select an option:\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "input('Select an option:\n",
    "        ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ageStr_to_ageNum(serie):\n",
    "    \"\"\"\n",
    "    INPUT -> serie df[] = ['61 years old', '57 years old', '32 years old'] -> full strings\n",
    "    OUPUT -> serie df[] = [ 61 57 32 45 41 1990 2000]                      -> only integers\n",
    "    \"\"\"\n",
    "    return serie.apply(lambda x: re.sub('\\D', '', x)).astype(int)\n",
    "\n",
    "def year_to_age(serie):\n",
    "    \"\"\"\n",
    "    INPUT -> serie:  df[] = [ 61 57 32 45 41 1990 2000]   -> ages + years (all ints)\n",
    "    OUTPUT -> serie: df[] = [ 61 57 32 45 41   30   20]   -> only ages    (all ints)\n",
    "    \"\"\"   \n",
    "    year_db = 2016 # DB is from this year!\n",
    "    return serie.apply(lambda x: year_db - x if int(x) > 200 else x)\n",
    "\n",
    "def year_update(serie):\n",
    "    \"\"\"\n",
    "    La tabla está en 2016, hay que actualizar datos para uqe no haya incongruencias entre Age y Age_Group\n",
    "    \"\"\"\n",
    "    year_now = datetime.today().year\n",
    "    year_db = 2016\n",
    "    return serie.apply(lambda x: (year_now - year_db) + x)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def countryCode_to_countryName(serie, web_page):\n",
    "    # CAMBIAR SEGÚN DICCIONARIO DE EUROPEAN COUNTRIES\n",
    "    \"\"\"\n",
    "    INPUT  ->      AT      FR     ES  -> alpha_2 code\n",
    "    OUTPUT -> Austria  France  Spain  -> full name\n",
    "    --------------------------------------------------------------------------------\n",
    "    Note: countries_code_alpha_2 is a dict from get_dictCountries()\n",
    "    \"\"\"\n",
    "    url = web_page\n",
    "    country_dictionary = get_dictCountries(url)\n",
    "    \n",
    "    return serie.apply(lambda x: country_dictionary[str(x)]) # Esto se puede hacer en la API\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def null_to_unknown(serie):\n",
    "    \"\"\"\n",
    "    INPUT  -> no  high     None  medium     None  low  no\n",
    "    OUTPUT -> no  high  unknown  medium  unknown  low  no\n",
    "    \n",
    "    Podria considerarse tb no... aquí hay interpretación de datos!\n",
    "    \"\"\"\n",
    "    return serie.apply(lambda x: 'unknown' if x == None else x)\n",
    "\n",
    "\n",
    "def gender_homogenization(serie):\n",
    "    \"\"\"\n",
    "    INPUT  -> female, FeMale, Fem, male, Male\n",
    "    OUTPUT ->      F,      F,   F,    M,    M\n",
    "    \"\"\"\n",
    "    serie = serie.apply(lambda x: re.sub('^f\\w+|^F\\w+', 'F', x))\n",
    "    serie = serie.apply(lambda x: re.sub('^m\\w+|^M\\w+', 'M', x))\n",
    "    return serie\n",
    "\n",
    "\n",
    "def context_homogenization(serie):\n",
    "    \"\"\"\n",
    "    INPUT  ->   urban  city  rural  Non-Rural Countryside  -> various types of response\n",
    "    OUTPUT ->   urban  urban rural      urban       rural  -> two types of response\n",
    "    ------------------------------------------------------------------------------------\n",
    "    LIST OF POSSIBLE ANSWERS TAKING INTO ACCOUNT serie count values\n",
    "    \"\"\"\n",
    "    urban_context = ['urban', 'city', 'non-rural', 'Non-Rural']\n",
    "    rural_context = ['rural', 'country', 'countryside', 'Country']\n",
    "    \n",
    "    return  ['urban_context' if response in urban_context \n",
    "        else 'rural_context' if response in rural_context \n",
    "        else None \n",
    "        for response in serie]\n",
    "\n",
    "\n",
    "\n",
    "def yes_no_to_bool(serie):\n",
    "    \"\"\"\n",
    "    Appliable to yes/no questions with multiple formats, to transform into boolean info\n",
    "    INPUT  -> YES yes Yes yES No NO nO no  -> type str\n",
    "    OUTPUT ->   1   1   1   1  0  0  0  0  -> type bool\n",
    "    \"\"\"\n",
    "    serie = serie.apply(lambda x: re.sub('^y\\w+|^Y\\w+', '1', x))\n",
    "    serie = serie.apply(lambda x: re.sub('^n\\w+|^N\\w+', '0', x)).astype(int)\n",
    "    return serie.astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################# EJERCICIO DE API ####\n",
    "\n",
    "def get_job_code(serie):\n",
    "    \"\"\"\n",
    "    In table career_info\n",
    "    INPUT  -> hash\n",
    "    OUTPUT -> dictionary w hash info provided by API\n",
    "    \"\"\"\n",
    "    json_dicts = []\n",
    "    uuid_db = serie.unique().tolist()\n",
    "    \n",
    "    for job_code in uuid_db:\n",
    "        response = requests.get(f'http://api.dataatwork.org/v1/jobs/{job_code}')\n",
    "        json_dicts.append(response.json())\n",
    "        \n",
    "    return json_dicts\n",
    "\n",
    "\n",
    "def normalized_jobs_col(coded_series, json_data):\n",
    "    \"\"\"\n",
    "    INPUT  -> None  <hash>                 --> coded_col\n",
    "    OUTPUT -> None  <job name as in API>   --> new_col\n",
    "    \"\"\"\n",
    "    new_col = [d.get('title')  for job_code in coded_series \n",
    "                               for d in json_data \n",
    "                               if d.get('uuid') == job_code]\n",
    "    # d.get('title') or d.get('normalized_job_title')\n",
    "    return new_col  # Con aply or merge tb\n",
    "\n",
    "\n",
    "################################################################################# SCKLEARN COSAS DE ML ####\n",
    "\n",
    "def separate_df_to_bools(df, cols_to_separate, cols_separated):\n",
    "    \"\"\"\n",
    "    INPUT  -> df[col].unique() = [range_1, range_2, range_3]\n",
    "    OUTPUT -> df[[range_1, range_2, range_3]] with boolean responses\n",
    "    \"\"\"\n",
    "    df_encoder = OneHotEncoder(dtype=bool, sparse=True)\n",
    "    df = pd.DataFrame(df_encoder.fit_transform(df[cols_to_separate]).toarray(),columns=cols_separated)\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def save_df_to_csv(df, path, name):\n",
    "    \n",
    "    print(f'\\t\\t ->Saving {df} in {path} as {name}')\n",
    "    path = '../' + f'{path}'\n",
    "    return df.to_csv(f'{path}/{name}.csv')\n",
    "    print('\\t\\t ->Job done!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1_ DF_PERSONAL_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        \n",
    "    # Paso 1_ normalización de columna Age: str -> int -> change years w/ ages -> update current year?\n",
    "    df_personal_info['age'] = ageStr_to_ageNum(df_personal_info['age'])\n",
    "    df_personal_info['age'] = year_to_age(df_personal_info['age'])\n",
    "    # df_personal_info['age'] = year_update(df_personal_info['age'])\n",
    "    \"\"\" El problema de actualizar la fecha es que hay que reevaluar los grupos de edad\"\"\"\n",
    "\n",
    "    # Paso 2_ String Operations: multiple inputs in binomial cols -> only 2 values for 2 options\n",
    "    df_personal_info['gender'] = gender_homogenization(df_personal_info['gender'])\n",
    "    df_personal_info['dem_has_children'] = yes_no_to_bool(df_personal_info['dem_has_children'])\n",
    "    \n",
    "    # Paso 3_ Separate cols for boolean options\n",
    "    initial_cols = ['gender', 'age_group']\n",
    "    final_cols = ['gender_Female', 'gender_Male', 'ageGroup_14_25', 'ageGroup_26_39', 'ageGroup_40_65', 'ageGroup_juvenile']\n",
    "    \n",
    "    new_bool_df = separate_df_to_bools(df_personal_info, initial_cols, final_cols)\n",
    "    df_personal_info = df_personal_info.join(other= new_bool_df, on=None, how='left', sort=False)\n",
    "    \n",
    "    # Paso 4_Guardar la tabla en local\n",
    "    save_df_to_csv(df_personal_info, \n",
    "                   path='data/processed', \n",
    "                   name= 'personal_info')\n",
    "\n",
    "except:\n",
    "    print('Something went wrong')\n",
    "\n",
    "finally:\n",
    "    \"\"\" MEMORY USAGE from 377.0+ KB to 367.6+ KB | FROM object(5) to bool(7), object(4) \"\"\"\n",
    "    print('Done cleaning df_personal_info!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal_info.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2_ DF COUNTRY_INFO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Country info is list_of_dfs[0]\"\"\"\n",
    "try:\n",
    "    initial_cols = ['rural']\n",
    "    final_cols = ['rural_context', 'urban_context']\n",
    "    \n",
    "    ### Here comes the dict from web scrapping\n",
    "    \n",
    "    # Paso 1_ transformar datos en cols en elementos más legibles\n",
    "    df_country_info['country_Names'] = countryCode_to_countryName(\n",
    "        serie= df_country_info['country_code'], \n",
    "        web_page= 'https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Country_codes')\n",
    "    \n",
    "    # Paso 1_ String Operations multiple inputs to binomial cols -> only 2 values from 2 options\n",
    "    df_country_info['rural'] = context_homogenization(df_country_info['rural'])\n",
    "    \n",
    "    # Paso 2_\n",
    "    new_bool_df = separate_df_to_bools(df_country_info, initial_cols, final_cols)\n",
    "    \n",
    "    df_country_info = df_country_info.join(other= new_bool_df, on=None, \n",
    "                                                               how='left', \n",
    "                                                               sort=False)\n",
    "\n",
    "    df_country_info.drop(columns='rural', inplace = True)\n",
    "    \n",
    "except:\n",
    "    print('Something went wrong with [acquire_table_career_info]')\n",
    "\n",
    "finally:\n",
    "    print('''\\t\\t\\t  >> Done cleaning df_career_info!. \n",
    "             \\t\\t\\t  >> Chekout /data/processed/''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_info.info(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3_ DF CAREER_INFO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Country info is list_of_dfs[0]\"\"\"\n",
    "try:\n",
    "    print(f'')\n",
    "    # Columnas a separar en booleanos\n",
    "    initial_cols  = ['dem_education_level']\n",
    "    final_cols = ['High_Ed', 'Low_Ed', 'Medium_Ed', 'No_Ed', 'Unknown_Ed']\n",
    "\n",
    "    # Paso 1_ cambiar columnas de yes/no -> booleanos + Nones to Unknown en col de valores cualitativos\n",
    "    df_career_info['dem_full_time_job'] = yes_no_to_bool(df_career_info['dem_full_time_job'])\n",
    "    df_career_info['dem_education_level'] = null_to_unknown(df_career_info['dem_education_level'])\n",
    "    \n",
    "    # Paso 2_ A traves de API, añadir columna de nombres de JOBS\n",
    "    json_job_data = get_job_code(df_career_info['normalized_job_code'])\n",
    "    df_career_info['normalized_job_name'] = normalized_jobs_col(df_career_info['normalized_job_code'], json_job_data)\n",
    "    \n",
    "    # Paso 3_ Creación de nuevas columnas, a partir de columna inicial\n",
    "    new_bool_df = separate_df_to_bools(df_career_info, initial_cols, final_cols)\n",
    "    df_career_info = df_career_info.join(other= new_bool_df, on=None, how='left', sort=False)\n",
    "\n",
    "    # Paso 4_ Eliminación de información redundante\n",
    "    cols_to_del = ['dem_education_level', 'normalized_job_code']\n",
    "    df_career_info.drop(columns= cols_to_del, inplace= True)\n",
    "    \n",
    "except:\n",
    "    print('Something went wrong with [acquire_table_career_info]')\n",
    "\n",
    "finally:\n",
    "    \"\"\"MEMORY USAGE from 301.7+ KB to 207.4+ KB | FROM objects(4) to bool(6), object(2) \"\"\"\n",
    "    print('Done cleaning df_career_info!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_career_info.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4_ DF POLL_INFO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_poll_info.info()\n",
    "\"\"\" dtypes: object(6) | memory usage: 452.4+ KB \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str_at_char(str_to_split, cutter):\n",
    "    if isinstance(str_to_split, str) and isinstance(cutter, str):\n",
    "        return re.split(cutter, str_to_split)[1].capitalize()\n",
    "    else:\n",
    "        print('EntryError [at split_str_at_char]: wrong type of inputs')\n",
    "    \n",
    "def get_uniqueResponses(serie, separator):\n",
    "    \"\"\"\n",
    "    This function searches for the uniques responses in a multiple choice response \n",
    "    presented as a concatenated string.\n",
    "    INPUT  ->  'E | F | C | D'   'D | A'    'C'   'E | B'  --> Unsorted concat strings\n",
    "    OUTPUT ->  ['E', 'F', 'C', 'D', 'A', 'B']              --> Unsorted unique strings\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(separator, str):\n",
    "            list_of_all_responses = set()\n",
    "            all_responses = set()\n",
    "\n",
    "            flattened_list_of_responses = reduce(lambda x,y: x+y, \n",
    "                                                 [item.split(separator) for item in serie.unique()])\n",
    "\n",
    "            for response in flattened_list_of_responses:\n",
    "                if response not in list_of_all_responses:\n",
    "                    list_of_all_responses.add(response)\n",
    "\n",
    "            return list(list_of_all_responses)\n",
    "        else:\n",
    "            print('EntryError [at get_uniqueResponses]: wrong type of inputs')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "def to_binary_matrix_of_equals(list_uniques, list_to_eval):\n",
    "    \n",
    "    list_uniques_lenghts = [len(i) for i in list_uniques]\n",
    "    \n",
    "    list_to_eval_iterabl = iter(list_to_eval)\n",
    "    list_to_eval_lenghts = list(reduce(lambda x,y: x+y, list_to_eval))\n",
    "\n",
    "    list_of_lists = []\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        for v in list_to_eval_lenghts:\n",
    "            arr = [len(i) for i in next(list_to_eval_iterabl)]\n",
    "            list_of_arrays = []\n",
    "\n",
    "            for len_num in arr:\n",
    "                list_of_arrays.append( np.where( np.array(list_uniques_lenghts) == len_num, 1, 0))\n",
    "\n",
    "            list_of_lists.append(list_of_arrays)\n",
    "            \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    flat_arrays = [np.sum(i, axis = 0) for i in list_of_lists]\n",
    "    binary_matrix = [i.tolist() for i in flat_arrays]\n",
    "    \n",
    "    return binary_matrix\n",
    "    \n",
    "\n",
    "####################################################################################  DONT NEED THIS  ######\n",
    "def length_str_nlist(nlist):\n",
    "    \"\"\"\n",
    "    INPUT   -> [['Hello'], ['Hola', 'Caracola!']] -> nested list of strings, diff len\n",
    "    OUTPUT  -> [[5], [4, 9]]                      -> nested list of integers, diff len\n",
    "    \"\"\"\n",
    "    graph_list_str_lenghts = []\n",
    "\n",
    "    # iterate through nested items whithout flattening list\n",
    "    # works for [[1,2], [3,4]]\n",
    "    for lsts in nlist:\n",
    "        graph_sublist_str_lenghts = []\n",
    "        \n",
    "        for i in lsts:\n",
    "            graph_sublist_str_lenghts.append(len(i))\n",
    "\n",
    "        graph_list_str_lenghts.append(graph_sublist_str_lenghts)\n",
    "        \n",
    "    return graph_list_str_lenghts\n",
    "\n",
    "\n",
    "def binary_matrix(list_uniques, eval_matrix):\n",
    "    \"\"\"\n",
    "    This function iterates through a list and searches for equalities into another list.\n",
    "    INPUT  -> [1,2,5,1,2,1,2,5]  + [1,2]   --> these are the lenghts of strings to search for equals\n",
    "    OUTPUT -> [1,0,0,1,0,1,0,0]    [1]     --> equality in string of len = 1\n",
    "              [0,1,0,0,1,0,1,0]    [2]     --> equality in string of len = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_lists = []\n",
    "    \n",
    "    # iterate through elements in nested lists without flattening list\n",
    "    for lst in eval_matrix:\n",
    "        list_of_arrays =[]\n",
    "        \n",
    "        for numb in lst:\n",
    "            list_of_arrays.append(np.where(np.array(list_uniques) == numb, 1, 0))\n",
    "        \n",
    "        list_of_lists.append(list_of_arrays)\n",
    "    \n",
    "    flat_arrays = [np.sum(i, axis = 0) for i in list_of_lists]\n",
    "    binary_matrix = [i.tolist() for i in flat_arrays]\n",
    "    \n",
    "    return binary_matrix\n",
    "\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice_col_to_df(serie, separator):\n",
    "    \"\"\"\n",
    "    Makes all the operations to return a boolean df with all the possible responses from each poll\n",
    "    Nested functions : get_uniqueResponses()   to_binany_matrix_of_equals()\n",
    "    \"\"\"\n",
    "    poll_info_allResponses = get_uniqueResponses(serie, separator)\n",
    "\n",
    "    graph_list_of_responses = serie.apply(lambda x: x.split(separator))\n",
    "\n",
    "    bin_matrix = to_binary_matrix_of_equals(poll_info_allResponses, graph_list_of_responses)\n",
    "\n",
    "    df = pd.DataFrame(bin_matrix, columns=poll_info_allResponses, dtype='bool') \n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_info['question_bbi_2016wave4_basicincome_effect'] = [split_str_at_char(response, 'Û_ ') \n",
    "                                                            if re.search('Û_ ', response)\n",
    "                                                            else response\n",
    "                                                            for response in df_poll_info['question_bbi_2016wave4_basicincome_effect']\n",
    "                                                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALTA AÑADIR LA COLUMNA DE UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_poll_basicincome_awareness = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_awareness'], ' | ')\n",
    "\n",
    "df_poll_basicincome_vote = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_vote'], separator= ' | ')\n",
    "\n",
    "df_poll_basicincome_effect = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_effect'], separator= ' | ')\n",
    "\n",
    "\n",
    "df_poll_basicincome_argumentsagainst = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_argumentsagainst'], separator= ' | ')\n",
    "\n",
    "df_poll_basicincome_argumentsfor = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_argumentsfor'], separator= ' | ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_poll_basicincome_argumentsagainst = multiple_choice_col_to_df(df_poll_info['question_bbi_2016wave4_basicincome_argumentsagainst'], separator= ' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_awareness.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_vote.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_effect.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_argumentsfor..info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_argumentsfor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_argumentsagainst.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poll_basicincome_argumentsagainst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLAS FINAL LIMPIADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar tablas en LOCAL para poder hacer wrangling con ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_personal_info\n",
    "\n",
    "df_country_info\n",
    "\n",
    "df_career_info\n",
    "\n",
    "df_poll_basicincome_awareness\n",
    "df_poll_basicincome_vote\n",
    "df_poll_basicincome_effect\n",
    "df_poll_basicincom_argumentsfor\n",
    "df_poll_basicincome_argumentsagainst\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 # getting the table to add data\n",
    "\n",
    "dfs = [df_career_info, df_country_info, df_personal_info]\n",
    "\n",
    "df_joined = reduce(lambda left,right: pd.merge(left,right,on='uuid'), dfs) #Apply\n",
    "\n",
    "df_final = df_joined[['country_Names', 'normalized_job_name', 'gender', 'dem_full_time_job']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### ESTO ES MI DIVIDENDO: La cantidad de gente con un determinado trabajo en un país, dividido por sexos\n",
    "\n",
    "df_2 = df_final.groupby(['country_Names','normalized_job_name','gender']).agg('count').reset_index()\n",
    "df_2.rename(columns={\"dem_full_time_job\": \"Quantity\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################### this is good good good ############\n",
    "# DIVIDENDO ?\n",
    "filtr = ['country_Names','normalized_job_name','gender']\n",
    "\n",
    "df_2 = df_final.assign(quantity = 1)\\\n",
    "                .groupby(['country_Names','normalized_job_name','gender'])\\\n",
    "                .agg('count')\\\n",
    "                .reset_index()\\\n",
    "                .drop(columns='dem_full_time_job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ESTO ES MI DIVIDOR: La cantidad de gente encuestada por pais\n",
    "\n",
    "df_4 = df_2.groupby(['country_Names'])['normalized_job_name'].nunique()\n",
    "df_5 = df_2.groupby(['country_Names', 'gender'], as_index = False)['normalized_job_name','Quantity'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.drop(columns='normalized_job_name', inplace=True, errors='raise')\n",
    "df_5 = df_5.rename(columns = {'Quantity': 'totals_per_gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_4.to_frame()\n",
    "df_4 = df_4.rename(columns={'normalized_job_name': 'totals_per_country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_2.join(df_4, on='country_Names', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_2 = df_5.join(df_4, on='country_Names', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtr = df_all['country_Names'] == 'France'\n",
    "df_all[filtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Percentage'] = round(df_all['Quantity'] / df_all['totals_per_country'] * 100, 2)\n",
    "df_filtr = df_all[filtr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHART 1\n",
    "\n",
    "# Tabla que muestra distribución según sexos de empleos (por país)\n",
    "# Falta por trabajar que me muestre la cantidad, no su existencia\n",
    "\"\"\"\n",
    "df_filtr.groupby(['gender', 'normalized_job_name']).size().unstack().plot(kind='bar',stacked=True, figsize=(14, 25))\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_filtr.plot(kind='bar',x='normalized_job_name',y='Percentage')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env] *",
   "language": "python",
   "name": "conda-env-jupyter_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
